---
title: "Bayesian GLMM Part4"
author: "Murray Logan"
date: today
date-format: "DD/MM/YYYY"
format: 
  html:
    ## Format
    theme: [default, ../public/resources/ws-style.scss]
    css: ../public/resources/ws_style.css
    html-math-method: mathjax
    ## Table of contents
    toc: true
    toc-float: true
    ## Numbering
    number-sections: true
    number-depth: 3
    ## Layout
    page-layout: full
    fig-caption-location: "bottom"
    fig-align: "center"
    fig-width: 4
    fig-height: 4
    fig-dpi: 72
    tbl-cap-location: top
    ## Code
    code-fold: false
    code-tools: true
    code-summary: "Show the code"
    code-line-numbers: true
    code-block-border-left: "#ccc"
    code-copy: true
    highlight-style: atom-one
    ## Execution
    execute:
      echo: true
      cache: true
    ## Rendering
    embed-resources: true
crossref:
  fig-title: '**Figure**'
  fig-labels: arabic
  tbl-title: '**Table**'
  tbl-labels: arabic
engine: knitr
output_dir: "docs"
documentclass: article
fontsize: 12pt
mainfont: Arial
mathfont: LiberationMono
monofont: DejaVu Sans Mono
classoption: a4paper
bibliography: ../public/resources/references.bib
---

```{r}
#| label: setup
#| include: false
#| cache: false

knitr::opts_chunk$set(cache.lazy = FALSE,
                      tidy = "styler")
options(tinytex.engine = "xelatex")
```

# Preparations

Load the necessary libraries

```{r}
#| label: libraries
#| output: false
#| eval: true
#| warning: false
#| message: false
#| cache: false
library(tidyverse) #for data wrangling
library(car)       #for regression diagnostics
library(broom)     #for tidy output
library(ggfortify) #for model diagnostics
library(knitr)     #for kable
library(emmeans)   #for estimating marginal means
library(MASS)      #for glm.nb
library(brms)
library(broom.mixed)
library(tidybayes)
library(bayesplot)
library(standist)   #for visualizing distributions
library(rstanarm)
library(cmdstanr)   #for cmdstan
library(ggeffects)
library(rstan)
library(DHARMa)
library(ggridges)
library(easystats)     #framework for stats, modelling and visualisation
library(patchwork)
library(modelsummary)
source('helperFunctions.R')
```

# Scenario

![Crab_shrimp_coral](../public/resources/crab_shrimp_coral.jpg){#fig-crabs width="400" height="284"}

To investigate synergistic coral defence by mutualist crustaceans,
@Mckeon-2012-1095 conducted an aquaria experiment in which colonies of a coral
species were placed in a tank along with a predatory sea star and one of four
symbiont combinations:

- no symbiont,
- a crab symbiont
- a shrimp symbiont
- both a crab and shrimp symbiont.

The experiments were conducted in a large octagonal flow-through seawater tank
that was partitioned into eight sections, which thereby permitted two of each of
the four symbiont combinations to be observed concurrently. The tank was left
overnight and in the morning, the presence of feeding scars on each coral colony
was scored as evidence of predation.  The experiments were repeated ten times,
each time with fresh coral colonies, sea stars and symbiont.

The ten experimental times represent blocks (random effects) within which the
symbiont type (fixed effect) are nested.

# Read in the data

```{r readData, results='markdown', eval=TRUE}
mckeon <- read_csv("../public/data/mckeon.csv", trim_ws = TRUE)
```
<!-- START_PRIVATE-->
::: {.panel-tabset}

## glimpse
```{r}
#| label: examinData
glimpse(mckeon)
```

## head
```{r}
## Explore the first 6 rows of the data
head(mckeon)
```

## str
```{r}
str(mckeon)
```

## Easystats (datawizard)
```{r}
mckeon |> datawizard::data_codebook()
```


## Skim (modelsummary)
```{r}
mckeon |> modelsummary::datasummary_skim()
mckeon |> modelsummary::datasummary_skim(by = c("SYMBIONT"))
```

:::

Since the response here is the presence or absence of predation (feeding scars),
a binomial distribution is appropriate.

We need to make sure that the categorical variable and the random effect are
defined as factors.  When doing so, it might be valuable to rearrange the order
of the fixed effect (SYMBIONT) such that the `none` group is considered the
first group.  This way, the other levels will all naturally be compared to this
level (hence it will be treated as a reference of control group). 

```{r processData, results='markdown', eval=TRUE, mhidden=TRUE}
mckeon <- mckeon %>%
  mutate(BLOCK = factor(BLOCK),
         SYMBIONT = factor(SYMBIONT, levels = c('none', 'crabs', 'shrimp', 'both')))
```

<!-- END_PRIVATE-->


# Exploratory data analysis

Model formula:
$$
y_i \sim{} \mathcal{N}(n, p_i)\\
ln\left(\frac{p_i}{1-p_1}\right) =\boldsymbol{\beta} \bf{X_i} + \boldsymbol{\gamma} \bf{Z_i}
$$

where $\boldsymbol{\beta}$ and $\boldsymbol{\gamma}$ are vectors of the fixed and random effects parameters respectively 
and $\bf{X}$ is the model matrix representing the overall intercept and effects of symbionts on the probability of the colony experiencing predation.
$\bf{Z}$ represents a cell means model matrix for the random intercepts associated with individual coral colonies.

<!-- START_PRIVATE-->
```{r eda1a, results='markdown', eval=TRUE, mhidden=TRUE}
ggplot(mckeon, aes(y=PREDATION, x=SYMBIONT)) +
    geom_point(position=position_jitter(width=0.2, height=0))+
    facet_wrap(~BLOCK)
```
<!-- END_PRIVATE-->

# Fit the model

<!-- START_PRIVATE-->
::: {.panel-tabset}
## rstanarm 
:::: {.panel-tabset}
### Using default priors
In `rstanarm`, the default priors are designed to be weakly informative. They
are chosen to provide moderate regularisation (to help prevent over-fitting) and
help stabilise the computations.

```{r fitModel1a, results='markdown', eval=TRUE, mhidden=TRUE, cache=TRUE}
mckeon.rstanarm <- stan_glmer(PREDATION ~ SYMBIONT + (1|BLOCK),
                           data = mckeon,
                           family = binomial(link = 'logit'),
                           iter = 5000,
                           warmup = 2000,
                           chains = 3,
                           thin = 5,
                           refresh = 0,
                           cores = 3)
```

```{r fitModel1b, results='markdown', eval=TRUE, mhidden=TRUE, cache=FALSE}
mckeon.rstanarm %>% prior_summary()
```
This tells us:

- for the intercept (when the family is binomial), a normal prior with
  a mean of 0 and a standard deviation of 2.5 is used. These are the
  default priors for bernoulli models.  A mean of 0 on a logit scale
  corresponds to a probability of 0.5.  Hence the prior expected value
  is 0.5.

- for the coefficients (in this case, just the slope), the default
  prior is a normal prior centred around 0 with a standard deviation
  of 2.5. For binomial models, this is then adjusted for the scale of
  the data by dividing the 2.5 by the standard deviation of the
  predictor (then rounded).

```{r fitModel1d, results='markdown', eval=TRUE, mhidden=TRUE, cache=FALSE}
model.matrix(~SYMBIONT, data=mckeon) %>%
    apply(2,sd) %>%
    (function(x) 2.5/x)
```


### Assessing priors
Lets now run with priors only so that we can explore the range of values they
allow in the posteriors.

```{r fitModel1f, results='markdown', eval=TRUE, mhidden=TRUE, cache=TRUE}
mckeon.rstanarm1 <- update(mckeon.rstanarm,  prior_PD=TRUE)
```

```{r fitModel1g, results='markdown', eval=TRUE, mhidden=TRUE, cache=FALSE}
mckeon.rstanarm1 %>% ggpredict() %>% plot(show_data=TRUE, jitter=c(0.5,0))
```

**Conclusions:**

- it is very difficult to assess the priors from the predicted
  posteriors when the posteriors are on the response scale as they
  will always approach values of 0 and 1 (no matter how wide they are
  on the link scale).

Interestingly, if we instead use `ggemmeans`, it will (perhaps
erroneously) generate the partial effects on the link scale (yet with
an incorrectly labelled y-axis).  Probability scale values of 0.99 and
0.01 (very large and small respectively) correspond to value of
approximately 4.6 and -4.6 respectively on the logit scale.  

In the following partial plot, the routine attempts to convert the
y-axes tick marks into percentages.  Hence a value of 0.1 is converted
to 10%.  Consequently, values of -5 and 5 are labelled as -500% and
500% respectively.  We know that on the probability scale, values must
asymptote towards 0 and 1.  Posterior intervals beyond -5 and 5 might
be considered wide.

```{r fitModel1g2, results='markdown', eval=TRUE, mhidden=TRUE, cache = FALSE}
mckeon.rstanarm1 %>% ggemmeans(~SYMBIONT) %>% plot(show_data=TRUE, jitter=c(0.5,0))
```

Alternatively, we could create the plot ourselves...

```{r fitModel1g3, results='markdown', eval=TRUE, mhidden=TRUE, cache = FALSE}
mckeon.rstanarm1 %>% emmeans(~SYMBIONT, type = 'link') %>%
    as.data.frame() %>%
    ggplot(aes(y = emmean, x = SYMBIONT)) +
    geom_hline(yintercept = c(5,-5), linetype = 'dashed') +
    geom_pointrange(aes(ymin = lower.HPD, ymax = upper.HPD)) +
    geom_point(data = mckeon, aes(y = PREDATION),
               position = position_jitter(width=0.2, height = 0),
               alpha=0.4, color = 'red')
```

### Defining priors

The following link provides some guidance about defining priors.
[https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations]

When defining our own priors, we typically do not want them to be scaled.

If we wanted to define our own priors that were less vague, yet still not likely
to bias the outcomes, we could try the following priors (mainly plucked out of
thin air):

- $\beta_0$: normal centred at 0 (since this is 0.5 on the logit
  scale) with a standard deviation of 2
  - mean of 0: since `logit(0.5)`
  - alternatively, an argument could be made for a mean of 0.51: since
    `logit(mean(mckeon$PREDATION))`
  - sd of 2: since this not too large on logit scale
- $\beta_1$: normal centred at 0 with a standard deviation of 0.5
  - sd of 0.5: since `model.matrix(~SYMBIONT, data=mckeon)[,-1] %>% apply(2,sd)` 
- $\Sigma$: decov with:
  - regularisation: the exponent for a LKJ prior on the correlation
    matrix.  A value of 1 (default) implies a joint uniform prior
  - concentration: the concentration parameter for a symmetric
    Dirichlet distribution.  A value of 1 (default) implies a joint
    uniform distribution
  - shape and scale: the shape and scale parameters for a gamma prior
    on the scale and scale parameters of the decov prior.  A value of
    1 for both (default) simplifies the gamma prior to a
    unit-exponential distribution.

I will also overlay the raw data for comparison.

```{r fitModel1h, results='markdown', eval=TRUE, mhidden=TRUE, cache=TRUE}
mckeon.rstanarm2 <- stan_glmer(PREDATION ~ SYMBIONT + (1|BLOCK),
                                data = mckeon,
                                family = binomial(link='logit'), 
                                prior_intercept = normal(0, 2.5, autoscale = FALSE),
                                prior = normal(0, 6, autoscale = FALSE),
                                prior_covariance = decov(1, 1, 1, 1), 
                                prior_PD = TRUE, 
                                iter = 5000,
                                warmup = 1000,
                                chains = 3,
                                thin = 5,
                                refresh = 0
                                )
```

```{r fitModel1i, results='markdown', eval=TRUE, mhidden=TRUE, cache=FALSE}
mckeon.rstanarm2 %>%
    ggpredict(~SYMBIONT) %>%
    plot(show_data = TRUE, jitter = c(0.5, 0))
mckeon.rstanarm2 %>% ggemmeans(~SYMBIONT) %>% plot(show_data=TRUE, jitter=c(0.5,0))
```

Now lets refit, conditioning on the data.

```{r fitModel1j, results='markdown', eval=TRUE, mhidden=TRUE, cache=TRUE, dependson='fitModel1h'}
mckeon.rstanarm3 <- update(mckeon.rstanarm2,  prior_PD=FALSE)
```
 
### Plotting prior and posterior

```{r modelFit1k, results='markdown', eval=TRUE, mhidden=TRUE, fig.width=8, fig.height=8}
posterior_vs_prior(mckeon.rstanarm3, color_by='vs', group_by=TRUE,
                   facet_args=list(scales='free_y'))
```

**Conclusions:**

- in each case, the prior is substantially wider than the posterior, suggesting
  that the posterior is not biased towards the prior.
  
```{r modelFit1l, results='markdown', eval=TRUE, mhidden=TRUE, fig.width=6, fig.height=4}
ggemmeans(mckeon.rstanarm3,  ~SYMBIONT) %>% plot(show_data=TRUE)
ggpredict(mckeon.rstanarm3,  ~SYMBIONT) %>% plot(show_data=TRUE)
```
::::
## brms 
:::: {.panel-tabset}
### Using default priors

In `brms`, the default priors are designed to be weakly informative.  They are
chosen to provide moderate regularisation (to help prevent over fitting) and
help stabilise the computations.

Unlike `rstanarm`, `brms` models must be compiled before they start sampling.
For most models, the compilation of the stan code takes around 45 seconds.

```{r fitModel2a, results='markdown', eval=TRUE, mhidden=TRUE, cache=TRUE, paged.print=FALSE, tidy.opts = list(width.cutoff = 80)}
mckeon.form <- bf(PREDATION | trials(1) ~ SYMBIONT + (1|BLOCK),
                  family=binomial(link='logit'))
options(width=150)
mckeon.form %>% get_prior(data = mckeon)
options(width=80)
```

### Defining priors

The following link provides some guidance about defining priors.
[https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations]

When defining our own priors, we typically do not want them to be scaled.

If we wanted to define our own priors that were less vague, yet still not likely
to bias the outcomes, we could try the following priors (mainly plucked out of
thin air):

- $\beta_0$: normal centred at 0 (since this is 0.5 on the logit
  scale) with a standard deviation of 2.5
  - mean of 0: since `logit(0.5)`
  - sd of 2: since this not too large on logit scale
  - alternatively, we could potentially use `logistic(0,1)`
- $\beta_1$: normal centred at 0 with a standard deviation of 6
  - sd of 6: since `2.5/model.matrix(~SYMBIONT, data=mckeon) %>% apply(2,sd)` 
- $\sigma_j$: half-cauchy with parameters 0 and 2.
- $\Sigma$: decov with:
  - regularisation: the exponent for a LKJ prior on the correlation matrix.  A
    value of 1 (default) implies a joint uniform prior
  - concentration: the concentration parameter for a symmetric Dirichlet
    distribution.  A value of 1 (default) implies a joint uniform distribution
  - shape and scale: the shape and scale parameters for a gamma prior on the
    scale and scale parameters of the
    decov prior.  A value of 1 for both (default) simplifies the gamma prior to
    a unit-exponential distribution.

Note, for hierarchical models, the model will tend to want to have a
large $sigma$ in order to fit the data better.  It is a good idea to
__regularise__ this tendency by applying a prior that has most mass
around zero.  Suitable candidates include:

- half-t: as the degrees of freedom approach infinity, this will approach a half-normal 
- half-cauchy: this is essentially a half-t with 1 degree of freedom
- exponential

I will also overlay the raw data for comparison.

```{r fitModel2h, results='markdown', eval=TRUE, mhidden=TRUE, cache=FALSE}
mckeon |> group_by(SYMBIONT) |>
  summarise(Mean = logit(mean(PREDATION)),
    Median = logit(median(PREDATION)),
    sd = logit(abs(sd(PREDATION))))
2.5/model.matrix(~SYMBIONT, data=mckeon) %>% apply(2,sd)

standist::visualize("student_t(3, 0, 2.5)",
                    "gamma(2,0.5)",
                    "cauchy(0,2)",
                    xlim=c(-10,25))
```

```{r fitModel2h1, results='markdown', eval=TRUE, mhidden=TRUE, cache=TRUE}
mckeon.form <- bf(PREDATION | trials(1) ~ SYMBIONT + (1|BLOCK),
                  family=binomial(link='logit'))
get_prior(mckeon.form, data = mckeon)
priors <-
    prior(normal(0, 1.5), class = 'Intercept') +
    prior(normal(0, 3), class = 'b') +
    prior(student_t(3, 0, 1.5), class = 'sd') 

mckeon.brm2 <- brm(mckeon.form, 
                  data = mckeon,
                  prior = priors,
                  sample_prior = 'only',
                  iter = 5000,
                  warmup = 2500,
                  chains = 3, cores = 3,
                  thin = 5,
                  control = list(adapt_delta = 0.99, max_treedepth =  20),
                  refresh = 0,
                  backend = "cmdstan"
                  )
```

```{r fitModel10, results='markdown', eval=TRUE, mhidden=TRUE, cache=FALSE}
mckeon.brm2 %>%
    ggpredict(~SYMBIONT) %>%
    plot(show_data = TRUE)

mckeon.brm2 %>%
    ggemmeans(~SYMBIONT) %>%
    plot(show_data = TRUE)

mckeon.brm2 |> 
    conditional_effects() |> 
    plot(points = TRUE)
```

```{r fitModel1i2, results='markdown', eval=TRUE, mhidden=TRUE, cache=FALSE}
mckeon.brm2 %>% emmeans(~SYMBIONT, type = 'link') %>%
    as.data.frame() %>%
    ggplot(aes(y = emmean, x = SYMBIONT)) +
    geom_hline(yintercept = c(5,-5), linetype = 'dashed') +
    geom_pointrange(aes(ymin = lower.HPD, ymax = upper.HPD)) +
    geom_point(data = mckeon, aes(y = PREDATION),
               position = position_jitter(width=0.2, height = 0),
               alpha=0.4, color = 'red')
```

Now lets refit, conditioning on the data.

```{r fitModel1j1, results='markdown', eval=TRUE, mhidden=TRUE, cache=TRUE, dependson='fitModel1h'}
mckeon.brm3 <- update(mckeon.brm2,
                      sample_prior = 'yes',
                      cores = 3,
                      refresh = 0)
save(mckeon.brm3, file = '../ws/testing/mckeon.brm3')
```
 
```{r partialPlot2h1b, results='markdown', eval=TRUE, mhidden=TRUE, fig.width=8, fig.height=5}
mckeon.brm3 %>%
    ggpredict(~SYMBIONT) %>%
    plot(show_data = TRUE)

mckeon.brm3 %>%
    ggemmeans(~SYMBIONT) %>%
    plot(show_data = TRUE)

mckeon.brm3 |> 
    conditional_effects() |> 
    plot(points = TRUE)

mckeon.brm3 %>% emmeans(~SYMBIONT, type = 'link') %>%
    as.data.frame() %>%
    ggplot(aes(y = emmean, x = SYMBIONT)) +
    geom_hline(yintercept = c(5,-5), linetype = 'dashed') +
    geom_pointrange(aes(ymin = lower.HPD, ymax = upper.HPD)) +
    geom_point(data = mckeon, aes(y = PREDATION),
               position = position_jitter(width=0.2, height = 0),
               alpha=0.4, color = 'red')
```


### Plotting prior and posterior

```{r posterior2h2, results='markdown', eval=TRUE}
mckeon.brm3 %>% get_variables()
mckeon.brm3 %>% hypothesis('SYMBIONTcrabs=0') %>% plot
mckeon.brm3 %>% hypothesis('SYMBIONTshrimp=0') %>% plot
```

```{r posterior2h2a, results='markdown', eval=TRUE, fig.width = 7, fig.height = 5}
mckeon.brm3 |> SUYR_prior_and_posterior()
```

### Random intercept/slope model

While we are here, we might like to explore a random intercept/slope model

```{r fitModel2h3, results='markdown', eval=TRUE, mhidden=TRUE, cache=TRUE}
mckeon.form <- bf(PREDATION | trials(1) ~ SYMBIONT + (SYMBIONT|BLOCK),
                  family=binomial(link='logit'))
get_prior(mckeon.form, mckeon)
priors <-
    prior(normal(0, 1.5), class = 'Intercept') +
    prior(normal(0, 3), class = 'b') +
    prior(student_t(3,0,1.5), class = 'sd', coef =  "Intercept", group =  "BLOCK") +
    prior(student_t(3,0,2), class = 'sd') +
    prior(lkj_corr_cholesky(1), class = 'cor')

mckeon.brm4 <- brm(mckeon.form, 
                  data = mckeon,
                  prior = priors,
                  sample_prior = 'yes',
                  iter = 5000,
                  warmup = 2500,
                  chains = 3, cores = 3,
                  thin = 5,
                  refresh = 0,
                  control = list(adapt_delta = 0.99, max_treedepth = 20),
                  backend = 'cmdstan'
                  )

save(mckeon.brm4, file = '../ws/testing/mckeon.brm4')
```

```{r posterior2k, results='markdown', eval=TRUE}
mckeon.brm4 %>% get_variables()
mckeon.brm4 %>% hypothesis('SYMBIONTcrabs=0') %>% plot
mckeon.brm4 %>% hypothesis('SYMBIONTshrimp=0') %>% plot
```

```{r posterior2k1, results='markdown', eval=TRUE, fig.width = 7, fig.height = 5}
mckeon.brm4 %>% SUYR_prior_and_posterior()
mckeon.brm3 %>% SUYR_prior_and_posterior()
mckeon.brm4 %>%
    conditional_effects() %>%
    plot(points = TRUE)
mckeon.brm3 %>%
    conditional_effects() %>%
    plot(points = TRUE)
mckeon.brm4 |> summary()
```

```{r posterior2k2, results='markdown', eval=TRUE, fig.width=10, fig.height=4}
mckeon.brm4 %>%
  posterior_samples %>%
  dplyr::select(-`lp__`) %>%
  pivot_longer(everything(), names_to = 'key') %>% 
  filter(!str_detect(key, '^r')) %>%
  mutate(Type = ifelse(str_detect(key, 'prior'), 'Prior', 'Posterior'),
         ## Class = ifelse(str_detect(key, 'Intercept'),  'Intercept',
         ##         ifelse(str_detect(key, 'b'),  'b', 'sigma')),
         Class = case_when(
               str_detect(key, '(^b|^prior).*Intercept$') ~ 'Intercept',
               str_detect(key, 'b_SYMBIONT.*|prior_b_SYMBIONT.*') &
               !str_detect(key, '.*:.*') ~ 'SYMBIONT',
               str_detect(key, 'sd') ~ 'sd',
               str_detect(key, '^cor|prior_cor') ~ 'cor',
             str_detect(key, 'sigma') ~ 'sigma'
             ),
         Par = str_replace(key, 'b_', '')) %>%
  ggplot(aes(x = Type,  y = value, color = Par)) +
  stat_pointinterval(position = position_dodge())+
  facet_wrap(~Class,  scales = 'free')
```

### Compare models

We can compare the two models using LOO

```{r fitModel2h3a, results='markdown', eval=TRUE, mhidden=TRUE, cache=TRUE}
(l.1 <- mckeon.brm3 %>% loo())
(l.2 <- mckeon.brm4 %>% loo())
loo_compare(l.1, l.2)
```

It appears that the random intercept/slope model is no better than the
simpler random intercept model.

```{r posterior2k20, results='markdown', eval=TRUE, fig.width=10, fig.height=4}
mckeon.brm4 %>%
  posterior_samples %>%
  dplyr::select(-`lp__`) %>%
  pivot_longer(everything(), names_to = 'key') %>% 
  filter(!str_detect(key, '^r')) %>%
  mutate(Type = ifelse(str_detect(key, 'prior'), 'Prior', 'Posterior'),
         Class = case_when(
             str_detect(key, '(^b|^prior).*Intercept$') ~ 'Intercept',
             str_detect(key, 'b_SYMBIONT.*|prior_b') ~ 'TREATMENT',
             str_detect(key, 'sd') ~ 'sd',
             str_detect(key, '^cor|prior_cor') ~ 'cor',
             str_detect(key, 'sigma') ~ 'sigma'),
         Par = str_replace(key, 'b_', '')) %>%
  ggplot(aes(x = Type,  y = value, color = Par)) +
  stat_pointinterval(position = position_dodge(), show.legend = FALSE)+
  facet_wrap(~Class,  scales = 'free')

```

::::
:::
<!-- END_PRIVATE-->


# MCMC sampling diagnostics 

<!-- START_PRIVATE-->
::: {.panel-tabset}

In addition to the regular model diagnostics checking, for Bayesian analyses, it
is also necessary to explore the MCMC sampling diagnostics to be sure that the
chains are well mixed and have converged on a stable posterior.

There are a wide variety of tests that range from the big picture, overall chain
characteristics to the very specific detailed tests that allow the experienced
modeller to drill down to the very fine details of the chain behaviour.
Furthermore, there are a multitude of packages and approaches for exploring
these diagnostics.

## brms 
:::: {.panel-tabset}
### bayesplot

The `bayesplot` package offers a range of MCMC diagnostics as well as Posterior
Probability Checks (PPC), all of which have a convenient `plot()` interface.
Lets start with the MCMC diagnostics.

```{r modelValidation2a, results='markdown', eval=TRUE, mhidden=TRUE, fig.width=6, fig.height=4}
available_mcmc()
```

Of these, we will focus on:

- trace: this plots the estimates of each parameter over the post-warmup
  length of each MCMC chain.  Each chain is plotted in a different shade of
  blue, with each parameter in its own facet.  Ideally, each **trace** should
  just look like noise without any discernible drift and each of the traces for
  a specific parameter should look the same (i.e, should not be displaced above
  or below any other trace for that parameter).

```{r modelValidation2b, results='markdown', eval=TRUE, mhidden=TRUE, fig.width=6, fig.height=4}
pars <- mckeon.brm3 |> get_variables()
pars <- pars %>% str_extract('^b.Intercept|^b_SYMBIONT.*|[sS]igma|^sd.*') %>%
    na.omit()
pars
mckeon.brm3 %>% mcmc_plot(type='trace', variables = pars)
#OR
mckeon.brm3 %>% mcmc_plot(type='trace',
                          variable = '^b.Intercept|^b_SYMBIONT.*|[sS]igma|^sd.*',
                          regex = TRUE)

```
  
   The chains appear well mixed and very similar
   
- acf_bar (auto-correlation function): plots the auto-correlation between successive
  MCMC sample lags for each parameter and each chain
  
```{r modelValidation2c, results='markdown', eval=TRUE, mhidden=TRUE, fig.width=6, fig.height=4}
mckeon.brm3 %>% mcmc_plot(type='acf_bar', variable = pars)
##OR
mckeon.brm3 %>% mcmc_plot(type='acf_bar',
                          variable = '^b.Intercept|^b_SYMBIONT.*|[sS]igma|^sd.*',
                          regex = TRUE)

```

   There is no evidence of auto-correlation in the MCMC samples

- rhat_hist: Rhat is a **scale reduction factor** measure of convergence between the chains.  The closer the
  values are to 1, the more the chains have converged.  Values greater than 1.05
  indicate a lack of convergence.  There will be an Rhat value for each
  parameter estimated.

```{r modelValidation2d, results='markdown', eval=TRUE, mhidden=TRUE, fig.width=6, fig.height=4}
mckeon.brm3 %>% mcmc_plot(type='rhat_hist')
```

  All Rhat values are below 1.05, suggesting the chains have converged.
  
- neff_hist (number of effective samples): the ratio of the number of effective
  samples (those not rejected by the sampler) to the number of samples provides
  an indication of the effectiveness (and efficiency) of the MCMC sampler.
  Ratios that are less than 0.5 for a parameter suggest that the sampler spent
  considerable time in difficult areas of the sampling domain and rejected more
  than half of the samples (replacing them with the previous effective sample).  
  
  If the ratios are low, tightening the priors may help.
  
```{r modelValidation2e, results='markdown', eval=TRUE, mhidden=TRUE, fig.width=6, fig.height=4}
mckeon.brm3 %>% mcmc_plot(type='neff_hist')
```

  Ratios all very high.

<details><summary>More diagnostics</summary>
```{r modelValidation2f, results='markdown', eval=TRUE, mhidden=TRUE, fig.width=6, fig.height=4}
mckeon.brm3 %>% mcmc_plot(type='combo', variable = pars)
mckeon.brm3 %>% mcmc_plot(type='violin', variable = pars)
```
</details>

### stan plots

The `rstan` package offers a range of MCMC diagnostics.
Lets start with the MCMC diagnostics.

Of these, we will focus on:

- stan_trace: this plots the estimates of each parameter over the post-warmup
  length of each MCMC chain. Each chain is plotted in a different colour, with
  each parameter in its own facet. Ideally, each **trace** should just look like
  noise without any discernible drift and each of the traces for a specific
  parameter should look the same (i.e, should not be displaced above or below
  any other trace for that parameter).
  
```{r modelValidation2g, results='markdown', eval=TRUE, mhidden=TRUE, fig.width=6, fig.height=4}
mckeon.brm4 %>% get_variables()
pars <- mckeon.brm4 %>% get_variables()
pars <- str_extract(pars, '^b_.*|^sigma$|^sd.*') %>% na.omit()

mckeon.brm4$fit %>%
    stan_trace(pars = pars)
mckeon.brm3$fit |> stan_trace()
```

   The chains appear well mixed and very similar
   
- stan_acf (auto-correlation function): plots the auto-correlation between successive
  MCMC sample lags for each parameter and each chain
  
```{r modelValidation2h, results='markdown', eval=TRUE, mhidden=TRUE, fig.width=6, fig.height=4}
mckeon.brm4$fit %>%
    stan_ac(pars = pars)
mckeon.brm3$fit |> stan_ac()
```

   There is no evidence of auto-correlation in the MCMC samples

- stan_rhat: Rhat is a **scale reduction factor** measure of convergence between the chains.  The closer the
  values are to 1, the more the chains have converged.  Values greater than 1.05
  indicate a lack of convergence.  There will be an Rhat value for each
  parameter estimated.

```{r modelValidation2i, results='markdown', eval=TRUE, mhidden=TRUE, fig.width=6, fig.height=4}
mckeon.brm3$fit %>% stan_rhat() 
```

  All Rhat values are below 1.05, suggesting the chains have converged.
  
- stan_ess (number of effective samples): the ratio of the number of effective
  samples (those not rejected by the sampler) to the number of samples provides
  an indication of the effectiveness (and efficiency) of the MCMC sampler.
  Ratios that are less than 0.5 for a parameter suggest that the sampler spent
  considerable time in difficult areas of the sampling domain and rejected more
  than half of the samples (replacing them with the previous effective sample).  
  
  If the ratios are low, tightening the priors may help.
  
```{r modelValidation2j, results='markdown', eval=TRUE, mhidden=TRUE, fig.width=6, fig.height=4}
mckeon.brm3$fit %>% stan_ess()
```

  Ratios all very high.

```{r modelValidation2k, results='markdown', eval=TRUE, mhidden=TRUE, fig.width=6, fig.height=4}
mckeon.brm4$fit %>%
    stan_dens(separate_chains = TRUE, pars = pars)
```

### ggmcmc

The `ggmean` package also as a set of MCMC diagnostic functions.
Lets start with the MCMC diagnostics.

Of these, we will focus on:

- ggs_traceplot: this plots the estimates of each parameter over the post-warmup
  length of each MCMC chain. Each chain is plotted in a different colour, with
  each parameter in its own facet. Ideally, each **trace** should just look like
  noise without any discernible drift and each of the traces for a specific
  parameter should look the same (i.e, should not be displaced above or below
  any other trace for that parameter).

```{r modelValidation2l, results='markdown', eval=TRUE, mhidden=TRUE, fig.width=6, fig.height=7}
## mckeon.ggs <- mckeon.brm3 %>% ggs(burnin = FALSE, inc_warmup = FALSE)
## mckeon.ggs %>% ggs_traceplot()
``` 

   The chains appear well mixed and very similar
   
- gss_autocorrelation (autocorrelation function): plots the autocorrelation between successive
  MCMC sample lags for each parameter and each chain
  
```{r modelValidation2m, results='markdown', eval=TRUE, mhidden=TRUE, fig.width=6, fig.height=7}
## ggs_autocorrelation(mckeon.ggs)
```

   There is no evidence of auto-correlation in the MCMC samples

- stan_rhat: Rhat is a **scale reduction factor** measure of convergence between the chains.  The closer the
  values are to 1, the more the chains have converged.  Values greater than 1.05
  indicate a lack of convergence.  There will be an Rhat value for each
  parameter estimated.

```{r modelValidation2n, results='markdown', eval=TRUE, mhidden=TRUE, fig.width=6, fig.height=4}
## ggs_Rhat(mckeon.ggs)
```

  All Rhat values are below 1.05, suggesting the chains have converged.
  
- stan_ess (number of effective samples): the ratio of the number of effective
  samples (those not rejected by the sampler) to the number of samples provides
  an indication of the effectiveness (and efficiency) of the MCMC sampler.
  Ratios that are less than 0.5 for a parameter suggest that the sampler spent
  considerable time in difficult areas of the sampling domain and rejected more
  than half of the samples (replacing them with the previous effective sample).  
  
  If the ratios are low, tightening the priors may help.
  
```{r modelValidation2o, results='markdown', eval=TRUE, mhidden=TRUE, fig.width=6, fig.height=4}
## ggs_effective(mckeon.ggs)
```

  Ratios all very high.

<details><summary>More diagnostics</summary>
```{r modelValidation2p, results='markdown', eval=TRUE, mhidden=TRUE, fig.width=6, fig.height=4}
## ggs_crosscorrelation(mckeon.ggs)
```

```{r modelValidation2q, results='markdown', eval=TRUE, mhidden=TRUE, fig.width=6, fig.height=4}
## ggs_grb(mckeon.ggs)
```
</details>

::::
:::
<!-- END_PRIVATE-->
# Model validation 
::: {.panel-tabset}
## brms 
:::: {.panel-tabset}
### pp check
Post predictive checks provide additional diagnostics about the fit of the
model.  Specifically, they provide a comparison between predictions drawn from
the model and the observed data used to train the model.

```{r modelValidation5a, results='markdown', eval=TRUE, mhidden=TRUE, fig.width=6, fig.height=4}
available_ppc()
```

- dens_overlay: plots the density distribution of the observed data (black line)
overlayed on top of 50 density distributions generated from draws from the model
(light blue).  Ideally, the 50 realisations should be roughly consistent with
the observed data.

```{r modelValidation5b, results='markdown', eval=TRUE, mhidden=TRUE, fig.width=6, fig.height=4}
mckeon.brm3 |> pp_check(type = 'dens_overlay', nsamples = 250)
```
The model draws appear to be consistent with the observed data.

- error_scatter_avg: this plots the observed values against the average
  residuals. Similar to a residual plot, we do not want to see any patterns in
  this plot.  Note, this is not really that useful for models that involve a
  binomial response

```{r modelValidation5c, results='markdown', eval=TRUE, mhidden=TRUE, fig.width=6, fig.height=4}
mckeon.brm4 %>% pp_check(type = 'error_scatter_avg')
```

This is not really interpretable

- intervals:  plots the observed data overlayed on top of posterior predictions
associated with each level of the predictor.  Ideally, the observed data should
all fall within the predictive intervals.


```{r modelValidation5e, results='markdown', eval=TRUE, mhidden=TRUE, fig.width=6, fig.height=4}
mckeon.brm4 %>% pp_check(group = 'BLOCK', type = 'intervals')
```

The `shinystan` package allows the full suite of MCMC diagnostics and posterior
predictive checks to be accessed via a web interface.

```{r modelValidation5g, results='markdown', eval=TRUE, mhidden=TRUE, fig.width=6, fig.height=4}
#library(shinystan)
#launch_shinystan(mckeon.brm2)
```

### DHARMa residuals

DHARMa residuals provide very useful diagnostics.  Unfortunately, we cannot
directly use the `simulateResiduals()` function to generate the simulated
residuals.  However, if we are willing to calculate some of the components
yourself, we can still obtain the simulated residuals from the fitted stan model.

We need to supply:

- simulated (predicted) responses associated with each observation.
- observed values
- fitted (predicted) responses (averaged) associated with each observation

```{r modelValidation6a, results='markdown', eval=TRUE, mhidden=TRUE, fig.width=8, fig.height=5}
preds <- mckeon.brm3 %>% posterior_predict(nsamples = 250,  summary = FALSE)
mckeon.resids <- createDHARMa(simulatedResponse = t(preds),
                            observedResponse = mckeon$PREDATION,
                            fittedPredictedResponse = apply(preds, 2, median),
                            integerResponse = TRUE)
plot(mckeon.resids, quantreg = TRUE)
```

```{r modelValidation6aa, results='markdown', eval=TRUE, mhidden=TRUE, fig.width=8, fig.height=8}
mckeon.resids <- make_brms_dharma_res(mckeon.brm3, integerResponse = FALSE)
wrap_elements(~testUniformity(mckeon.resids)) +
               wrap_elements(~plotResiduals(mckeon.resids, form = factor(rep(1, nrow(mckeon))))) +
               wrap_elements(~plotResiduals(mckeon.resids, quantreg = FALSE)) +
               wrap_elements(~testDispersion(mckeon.resids))

```
**Conclusions:**

- the simulated residuals do not suggest any issues with the residuals
- there is no evidence of a lack of fit.

::::
:::
<!-- END_PRIVATE-->
# Partial effects plots 

<!-- START_PRIVATE-->
::: {.panel-tabset}
## brms 
:::: {.panel-tabset}
### conditional_effects

```{r partialPlot2d, results='markdown', eval=TRUE, mhidden=TRUE, fig.width=8, fig.height=5}
mckeon.brm3 |> 
    conditional_effects() |> 
    plot(points = TRUE)
```

### ggpredict

```{r partialPlot2a, results='markdown', eval=TRUE, mhidden=TRUE, fig.width=8, fig.height=5}
mckeon.brm3 %>%
    ggpredict() %>%
    plot(show_data = TRUE, jitter=c(0.5,0))
```


### ggemmeans

```{r partialPlot2b, results='markdown', eval=TRUE, mhidden=TRUE, fig.width=8, fig.height=5}
mckeon.brm3 %>%
    ggemmeans(~SYMBIONT) %>%
    plot(show_data = TRUE, jitter=c(0.5,0)) 
```

### fitted_draws
    
```{r partialPlot2c, results='markdown', eval=TRUE, mhidden=TRUE, fig.width=8, fig.height=5}
## Partial residuals in binomial models are too confusing for the average viewer
## as they will yeild values that are not exactly 0 or 1 and this seems wrong.
## Partial.obs <- mckeon.brm3$data %>%
##     mutate(Pred = predict(mckeon.brm3, re.form=NA)[,'Estimate'],
##            Resid = resid(mckeon.brm3)[,'Estimate'],
##            Obs = Pred + Resid)

mckeon.brm3 %>%
    epred_draws(newdata = mckeon, re_formula = NA) %>%
    median_hdci() %>%
    ggplot(aes(x = SYMBIONT, y = .epred)) +
    geom_pointrange(aes(ymin = .lower, ymax = .upper)) + 
    geom_line() +
    ## geom_point(data = Partial.obs,  aes(y = Obs,  x = SYMBIONT),
    ##            position = position_nudge(x = 0.1, y = 0), color = "red") +
    geom_point(data = mckeon,  aes(y = PREDATION,  x = SYMBIONT), alpha=0.2,
               position = position_jitter(width= 0.2, height = 0))
```

::::
:::
<!-- END_PRIVATE-->

# Model investigation

<!-- START_PRIVATE-->
::: {.panel-tabset}
## brms 
:::: {.panel-tabset}
`brms` captures the MCMC samples from `stan` within the returned list.
There are numerous ways to retrieve and summarise these samples.  The first
three provide convenient numeric summaries from which you can draw conclusions,
the last four provide ways of obtaining the full posteriors. 

### summary

The `summary()` method generates simple summaries (mean, standard deviation as
well as 10, 50 and 90 percentiles).

```{r summariseModel2a, results='markdown', eval=TRUE, mhidden=TRUE, fig.width=8, fig.height=5}
mckeon.brm4 %>% summary()
```

```{r summariseModel2a1, results='markdown', eval=TRUE, mhidden=TRUE, fig.width=8, fig.height=5, echo=FALSE}
mckeon.sum <- summary(mckeon.brm3)
```

**Conclusions:**

- the coefficients are presented on a logit scale.  Whilst this is not relevant
  for the purpose of inference testing, it does make it difficult to interpret
  the coefficients.
- if we exponentiate the coefficients ($log(\frac{\rho}{1-\rho})$ ->
  $\frac{\rho}{1-\rho}$), they will be presented on a odds ratio scale, and thus:
  - the intercept (none symbionts) will be 
  `r as.numeric(round(exp(mckeon.sum$fixed[1,1]), 2))`.  That is, corals without a
    symbiont are `r as.numeric(round(exp(mckeon.sum$fixed[1,1]), 2))` times more
    likely to be predated on than not predated on.  The odds of predation in
    this the absence of symbionts is `r as.numeric(round(exp(mckeon.sum$fixed[1,1]), 2))`:1.
  - in the presence of a crab symbiont, the odds of being predated on are only 
  `r as.numeric(round(exp(mckeon.sum$fixed[2, 1]), 2))` times that of the none
    symbiont group.  That is, in the presence of a crab symbiont, the odds of
    predation decline by `r 100*(1-as.numeric(round(exp(mckeon.sum$fixed[2,1]), 2)))`%.
  - in the presence of a shrimp symbiont, the odds of being predated on are only 
  `r as.numeric(round(exp(mckeon.sum$fixed[3, 1]), 2))` times that of the none
    symbiont group.  That is, in the presence of a shrimp symbiont, the odds of
    predation decline by `r 100*(1-as.numeric(round(exp(mckeon.sum$fixed[3, 1]), 2)))`%.
  - in the presence of both crab and shrimp symbionts, the odds of being predated on are only 
  `r as.numeric(round(exp(mckeon.sum$fixed[4, 1]),2))` times that of the none
    symbiont group.  That is, in the presence of both crab and shrimp symbiont, the odds of
    predation decline by `r 100*(1-as.numeric(round(exp(mckeon.sum$fixed[4, 1]),2)))`%.
- if we back-transform the intercept full to the response scale (probability
  scale), ($log(\frac{\rho}{1-\rho})$ -> $\rho$), the intercept is interpreted
  as the probability that corals will be predated in the absence of of symbionts
  is `r round(plogis(as.numeric(mckeon.sum$fixed[1,1]),2))`

### as_draws_df (posteriors)

```{r summariseModel2bm, results='markdown', eval=TRUE, mhidden=TRUE, fig.width=8, fig.height=5,echo=FALSE}
mckeon.brm3 %>% as_draws_df()
mckeon.brm3 |> 
  as_draws_df() |> 
  mutate(across(everything(), exp)) |> 
  summarise_draws(
    median,
    HDInterval::hdi,
    Pl = ~mean(.x < 1),
    Pg = ~mean(.x > 1),
    rhat,
    ess_bulk,
    ess_tail
  ) |>
  knitr::kable()

mckeon.brm3 |>
    as_draws_df() |>
    exp() |>
    dplyr::select(matches("^b_.*|^sd_.*")) |> 
  summarise_draws(
    median,
    HDInterval::hdi,
    Pl = ~mean(.x < 1),
    Pg = ~mean(.x > 1),
    rhat,
    ess_bulk,
    ess_tail
  ) |>
  knitr::kable()
```

### tidyMCMC

```{r summariseModel2b, results='markdown', eval=TRUE, mhidden=TRUE, fig.width=8, fig.height=5}
mckeon.brm3$fit %>%
    tidyMCMC(estimate.method = 'median',
             conf.int = TRUE,  conf.method = 'HPDinterval',
             rhat = TRUE, ess = TRUE)
```
```{r summariseModel2b1, results='markdown', eval=TRUE, mhidden=TRUE, fig.width=8, fig.height=5,echo=FALSE}
mckeon.tidy <- tidyMCMC(mckeon.brm3$fit, estimate.method='median',
                         conf.int=TRUE,  conf.method='HPDinterval',
                         rhat=TRUE, ess=TRUE)
```

**Conclusions:**

see above

### gather_draws

Due to the presence of a log transform in the predictor, it is better to use the
regex version.
```{r summariseModel2c, results='markdown', eval=TRUE, mhidden=TRUE, fig.width=8, fig.height=5}
mckeon.brm3 %>% get_variables()
mckeon.draw <- mckeon.brm3 %>%
    gather_draws(`b.Intercept.*|b_SYMBIONT.*`,  regex=TRUE)
mckeon.draw
```

We can then summarise this

```{r summariseModel2c1, results='markdown', eval=TRUE, mhidden=TRUE, fig.width=8, fig.height=5}
mckeon.draw %>% median_hdci
## On a odd ratio scale
mckeon.draw %>%
    mutate(.value = exp(.value)) %>%
    median_hdci
```

```{r summariseModel2c3, results='markdown', eval=TRUE, mhidden=TRUE, fig.width=8, fig.height=5,echo=FALSE}
mckeon.gather <- mckeon.brm3 %>%
    gather_draws(`b_Intercept.*|b_SYMBIONT.*`,  regex=TRUE) %>%
    median_hdci
```

```{r summariseModel2c4, results='markdown', eval=TRUE, mhidden=TRUE, fig.width=8, fig.height=5,echo=TRUE}
mckeon.brm3 %>%
    gather_draws(`b_Intercept.*|b_SYMBIONT.*`, regex=TRUE) %>% 
    ggplot() +
    geom_vline(xintercept=0, linetype='dashed') +
    stat_slab(aes(x = .value, y = .variable,
                  fill = stat(ggdist::cut_cdf_qi(cdf,
                                                 .width = c(0.5, 0.8, 0.95), 
                                                 labels = scales::percent_format())
                              )), color='black') + 
    scale_fill_brewer('Interval', direction = -1, na.translate = FALSE) 

mckeon.brm3 %>% 
    gather_draws(`.Intercept.*|b_SYMBIONT.*`, regex=TRUE) %>% 
    ggplot() + 
    geom_vline(xintercept = 0, linetype='dashed') +
    stat_halfeye(aes(x=.value,  y=.variable)) +
    theme_classic()
```

### bayesplot

```{r summariseModel2j, results='markdown', eval=TRUE, mhidden=TRUE, fig.width=8, fig.height=5}
mckeon.brm3$fit %>% plot(type='intervals') 
```

### half-eye (ggdist)

```{r summariseModel2ka, results='markdown', eval=TRUE, mhidden=TRUE, fig.width=8, fig.height=5,echo=TRUE}
mckeon.brm3 %>% 
    gather_draws(`^b_.*`, regex=TRUE) %>% 
    filter(.variable != 'b_Intercept') %>%
    ggplot() + 
    stat_halfeye(aes(x=.value,  y=.variable)) +
    facet_wrap(~.variable, scales='free')

mckeon.brm3 %>% 
    gather_draws(`^b_.*`, regex=TRUE) %>% 
    filter(.variable != 'b_Intercept') %>%
    ggplot() + 
    stat_halfeye(aes(x=.value,  y=.variable)) +
    geom_vline(xintercept = 0, linetype = 'dashed')
```

### density ridges (ggridges)

```{r summariseModel2c7, results='markdown', eval=TRUE, mhidden=TRUE, fig.width=8, fig.height=5,echo=TRUE}
mckeon.brm3 %>% 
    gather_draws(`^b_.*`, regex=TRUE) %>% 
    filter(.variable != 'b_Intercept') %>%
    ggplot() +  
    geom_density_ridges(aes(x=.value, y = .variable), alpha=0.4) +
    geom_vline(xintercept = 0, linetype = 'dashed')
##Or in colour
mckeon.brm3 %>% 
    gather_draws(`^b_.*`, regex=TRUE) %>% 
    filter(.variable != 'b_Intercept') %>%
    ggplot() + 
    geom_density_ridges_gradient(aes(x=(.value),
                                     y = .variable,
                                     fill = stat(x)),
                                 alpha=0.4, colour = 'white',
                                 quantile_lines = TRUE,
                                 quantiles = c(0.025, 0.975)) +
    geom_vline(xintercept = 1, linetype = 'dashed') +
    scale_x_continuous() +
    scale_fill_viridis_c(option = "C") 

## Fractional scale
mckeon.brm3 %>% 
    gather_draws(`^b_.*`, regex=TRUE) %>% 
    filter(.variable != 'b_Intercept') %>%
    ggplot() + 
    geom_density_ridges_gradient(aes(x=exp(.value),
                                     y = .variable,
                                     fill = stat(x)),
                                 alpha=0.4, colour = 'white',
                                 quantile_lines = TRUE,
                                 quantiles = c(0.025, 0.975)) +
    geom_vline(xintercept = 1, linetype = 'dashed') +
    scale_x_continuous(trans = scales::log2_trans()) +
    scale_fill_viridis_c(option = "C") 
```
 
### tidy_draws

```{r summariseModel2d, results='markdown', eval=TRUE, mhidden=TRUE, fig.width=8, fig.height=5}
mckeon.brm3 %>% tidy_draws()
```

### spread_draws

```{r summariseModel2e, results='markdown', eval=TRUE, mhidden=TRUE, fig.width=8, fig.height=5}
mckeon.brm3 %>% spread_draws(`.*Intercept.*|b_SYMBIONT.*`,  regex=TRUE)
```
	
### posterior_samples
```{r summariseModel2f, results='markdown', eval=TRUE, mhidden=TRUE, fig.width=8, fig.height=5}
mckeon.brm3 %>% posterior_samples() %>% as_tibble()
```

### $R^2$

```{r summariseModel2g, results='markdown', eval=TRUE, mhidden=TRUE, fig.width=8, fig.height=5}
mckeon.brm3 %>%
    bayes_R2(re.form = NA, summary=FALSE) %>%
    median_hdci
mckeon.brm3 %>%
    bayes_R2(re.form = ~(1|BLOCK), summary=FALSE) %>%
    median_hdci
## if we had random intercept/slope
mckeon.brm4 %>%
    bayes_R2(re.form = ~(SYMBIONT|BLOCK), summary=FALSE) %>%
    median_hdci
```

### Modelsummary
```{r}
#| label: modelsummary
#| results: markup
#| eval: true
#| echo: true
#| cache: false
mckeon.brm4 |> modelsummary(
  statistic = c("conf.low", "conf.high"),
  shape = term ~ statistic,
  exponentiate = FALSE
)
```

```{r}
#| label: modelsummary_plot
#| results: markup
#| eval: true
#| echo: true
#| cache: false
mckeon.brm4 |> modelplot(exponentiate = FALSE)
```

::::
:::
<!-- END_PRIVATE-->

# Further analyses

<!-- START_PRIVATE-->

In addition to comparing each of the symbiont types against the control group of
no symbionts, it might be interesting to investigate whether there are any
differences between the predation protection provided by crabs and shrimp, as
well as whether having both crabs and shrimp symbionts is different to only a
single symbiont type.

These contrasts can be explored via specific contrasts.

| SYMBIONT | Crab vs Shrimp | One vs Both  | None vs Symbiont |
| -------- | -------------- | ------------ | ---------------- |
| none     | 0              | 0            | 1                |
| crab     | 1              | 1/2          | -1/3             |
| shrimp   | -1             | 1/2          | -1/3             |
| both     | 0              | -1           | -1/3             |

: Contrast coefficients {#tbl-xmat .table-condensed}
	
::: {.panel-tabset}
## brms {.tabset .tabset-pills}
:::: {.panel-tabset}
### Pairwise comparisons

```{r posthoc1a, results='markdown', eval=TRUE, mhidden=TRUE}
mckeon.brm4 %>%
    emmeans(~SYMBIONT, type='response') %>%
    pairs()

mckeon.em <-
  mckeon.brm4 %>%
  emmeans(~SYMBIONT, type='link') %>%
  pairs() %>%
  gather_emmeans_draws() |> 
  mutate(.value = exp(.value)) |>
  summarise(median_hdci(.value),
    Pl = mean(.value < 1),
    Pg = mean(.value > 1)
    )

## On the fractional scale
mckeon.em <- mckeon.brm4 %>%
    emmeans(~SYMBIONT, type='link') %>%
    pairs() %>%
    gather_emmeans_draws() %>%
    mutate(Eff=exp(.value),
           PEff=100*(Eff-1))#,
             #Prob = plogis(.value))
mckeon.em %>% head
mckeon.em %>%
  group_by(contrast) %>%
  dplyr::select(contrast, Eff) %>%
  median_hdi
mckeon.em %>%
  group_by(contrast) %>%
  summarize(Prob=sum(Eff>1)/n())
## On a probability scale
mckeon.em <- mckeon.brm3 %>%
    emmeans(~SYMBIONT, type='link') %>%
    regrid() %>%
    pairs() %>%
    gather_emmeans_draws() %>%
    mutate(Eff=.value)#,
mckeon.em %>% head
mckeon.em %>%
  group_by(contrast) %>%
  dplyr::select(contrast, Eff) %>%
  median_hdi

## Cell means
mckeon.em = emmeans(mckeon.brm3, ~SYMBIONT, type='link') %>%
      gather_emmeans_draws()
mckeon.em %>% mutate(P=plogis(.value)) %>% median_hdci(P)
```

### Specific contrasts

```{r posteriors1a, results='markdown', eval=TRUE, mhidden=TRUE}
cmat <- cbind(
    "Crab vs shrimp" =c(0,1,-1,0),
    "Both vs One"=c(0,-1/2,-1/2,1),
    "Any vs None"=c(-1, 1/3, 1/3, 1/3)
)

mckeon.em <- mckeon.brm3 |> 
    emmeans(~SYMBIONT, type = 'response') |> 
    contrast(method = list(cmat)) 

mckeon.em <-
  mckeon.brm3 %>%
    emmeans(~SYMBIONT, type='link') %>%
    contrast(method=list(cmat)) %>%
    gather_emmeans_draws() %>%
  mutate(Fit=exp(.value)) |>
  summarise(median_hdci(Fit),
    Pl =  mean(Fit < 0), 
    Pg =  mean(Fit > 0)
    )

newdata <- emmeans(mckeon.brm3, ~SYMBIONT, type = "response") %>% as.data.frame()
head(newdata)
ggplot(newdata, aes(y=prob, x=SYMBIONT)) +
    geom_pointrange(aes(ymin=lower.HPD, ymax=upper.HPD))
```

### R^2 

```{r R21a, results='markdown', eval=TRUE, mhidden=TRUE}
mckeon.brm3 %>% bayes_R2(re.form=NA)
mckeon.brm3 %>% bayes_R2(re.form=NA, summary=FALSE) %>% median_hdci()
mckeon.brm3 %>% bayes_R2(re.form=~(1|BLOCK), summary=FALSE) %>% median_hdci()
## for random intercept/slope model
mckeon.brm4 %>% bayes_R2(re.form=~(SYMBIONT|BLOCK), summary=FALSE) %>% median_hdci()
```

::::
:::
<!-- END_PRIVATE-->

# References
